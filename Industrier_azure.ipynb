{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X30x8VBlTZlx"
      },
      "source": [
        "# Funktioner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1616408512454
        },
        "id": "ikwLYoByBYIy"
      },
      "outputs": [],
      "source": [
        "# Preprocessing data\n",
        "\n",
        "def ml_pipeline (fil,industri):\n",
        "  # importing df and basic cleaning\n",
        "  df_ml = pd.read_csv(fil)\n",
        "  df_ml[\"Forecasttidspunkt\"] = pd.to_datetime(df_ml[\"Forecasttidspunkt\"])\n",
        "  df_ml[\"periode_regnskabstal\"] = pd.to_datetime(df_ml[\"periode_regnskabstal\"])\n",
        "  df_ml.set_index(\"Forecasttidspunkt\",inplace=True)\n",
        "\n",
        "  #Dropping non relevant columns\n",
        "  df_ml.rename(columns={\"CUSIP\":\"cusip\"},inplace=True)\n",
        "  list_drop = [\"SHROUT\",\"company_name\",\"cusip\",\"analyst_EPS_mean\",\"analyst_high\",\"analyst_low\",\"analyst_std_mean\",\"periode_regnskabstal\",\"PERMNO\",\"date\",\"slutmåned\",\"Instrument\"]\n",
        "  df_ml.drop(list_drop,axis=1,inplace=True,errors=\"ignore\")\n",
        "\n",
        "  # Creating year and month\n",
        "  df_ml[\"month\"] = df_ml.index.month\n",
        "  df_ml[\"year\"] = df_ml.index.year\n",
        "  df_ml = df_ml.astype({'GVKEY': 'category'})\n",
        "  df_ml = df_ml.astype({'industry_fama': 'category'})\n",
        "  df_ml.sort_index(inplace=True)\n",
        "  \n",
        "  # New features og duplikat kolonner\n",
        "  df_ml[\"volume_usd\"] = df_ml[\"ALTPRC\"] * df_ml[\"VOL\"]\n",
        "  df_ml[\"Div_yield\"] = df_ml[\"DPS_ex_date(dvpsxq)\"] / df_ml[\"ALTPRC\"]\n",
        "  df_ml.drop([\"PRC\",\"adj_close\"],axis=1,inplace=True)\n",
        "\n",
        "  columns_drop_list = [\"Assets_total(Atq)\",\"merafkast\"]\n",
        "  df_ml.drop(columns_drop_list,axis=1,inplace=True)\n",
        "\n",
        "\n",
        "  # Lagging variable\n",
        "\n",
        "  columns_lag = ['EPS_actual', 'Accounts_payable(Apq)',\n",
        "       'Assets_total(Atq)', 'COGS(Cogsq)',\n",
        "       'Common_equity(Ceqq)', 'DPS_ex_date(dvpsxq)', 'Deprect_and_ammor(Dpq)',\n",
        "       'EPS_lagged', 'GVKEY', 'Income taxes_total(Txtq)',\n",
        "       'Non_operating_income(Nopiq)', 'Operating_income_after_deprec(Oiadpq)',\n",
        "       'Opex_total(Xoprq)', 'PP&E_total_net(Ppentq)','PRC',\n",
        "       'Pretax_income(Piq)', 'Receviables(Rectq)', 'Revenue_total(Revtq)',\n",
        "    'VOL', 'adj_return','adj_close','market_cap', 'niq', 'industry_return', 'merafkast', 'ALTPRC','volume_usd','Div_yield']\n",
        "\n",
        "  df_lag = df_ml.copy()\n",
        "  df_lag = df_lag[df_lag.columns.intersection(columns_lag)]\n",
        "  df_lag_new = df_lag.copy()\n",
        "\n",
        "  for column in df_lag.columns:\n",
        "    for i in range(1,6):\n",
        "      df_lag_new[f'{column}_{i}'] = df_lag.groupby(\"GVKEY\")[f'{column}'].shift(i).values\n",
        "\n",
        "  columns_to_choose = ['Assets_total(Atq)','Accounts_payable(Apq)', 'COGS(Cogsq)',\n",
        "       'Common_equity(Ceqq)', 'DPS_ex_date(dvpsxq)', 'Deprect_and_ammor(Dpq)',\n",
        "       'EPS_lagged', 'Income taxes_total(Txtq)',\n",
        "       'Non_operating_income(Nopiq)', 'Operating_income_after_deprec(Oiadpq)',\n",
        "       'Opex_total(Xoprq)', 'PP&E_total_net(Ppentq)',\n",
        "       'Pretax_income(Piq)', 'Receviables(Rectq)', 'Revenue_total(Revtq)',\n",
        "       'market_cap', 'niq',\"Div_yield\",\"ALTPRC\",'adj_return',\"industry_return\",\"merafkast\",'VOL','volume_usd','PRC','adj_close']\n",
        "  col_lag_choose = []\n",
        "  for element in columns_to_choose:\n",
        "    for i in range(1,6):\n",
        "      col_lag_choose.append(f'{element}_{i}')\n",
        "  col_lag_choose.append(\"GVKEY\")\n",
        "\n",
        "  # Vælger kun de endelige features\n",
        "  df_lag_new = df_lag_new[df_lag_new.columns.intersection(col_lag_choose)]\n",
        "\n",
        "  # Merge lags og oprindelig dataframe sammen\n",
        "  df_ml = df_ml.reset_index().merge(df_lag_new.reset_index(),how=\"inner\",on=[\"GVKEY\",\"Forecasttidspunkt\"])\n",
        "\n",
        "  # Fikse indeks og erstatte NA i lags med NA\n",
        "\n",
        "  numeric_columns = df_ml.select_dtypes(include=['number']).columns\n",
        "  df_ml[numeric_columns] = df_ml[numeric_columns].fillna(0)\n",
        "\n",
        "  df_ml.set_index(\"Forecasttidspunkt\",inplace=True)\n",
        "  df_ml = df_ml[df_ml.industry_fama==industri]\n",
        "  \n",
        "  cutoff_date = \"2016-06-30\"\n",
        "  validation_start = \"2016-09-30\"\n",
        "  validation_end = \"2018-06-30\"\n",
        "  test_start = \"2018-09-30\"\n",
        "\n",
        "  training_df = df_ml.loc[:cutoff_date,:]\n",
        "  validation_df = df_ml.loc[validation_start:validation_end,:]\n",
        "  test_df = df_ml.loc[test_start:,:]\n",
        "\n",
        "  training_df_cv =  df_ml.loc[:validation_end,:]\n",
        "\n",
        "# X og Y\n",
        "\n",
        "  training_y = training_df[\"EPS_actual\"]\n",
        "  validatation_y = validation_df[\"EPS_actual\"]\n",
        "  test_y = test_df[\"EPS_actual\"]\n",
        "  training_y_cv = training_df_cv[\"EPS_actual\"]\n",
        "\n",
        "  training_x = training_df.drop(\"EPS_actual\",axis=1)\n",
        "  training_x_cv = training_df_cv.drop(\"EPS_actual\",axis=1)\n",
        "  validatation_x = validation_df.drop(\"EPS_actual\",axis=1)\n",
        "  test_x = test_df.drop(\"EPS_actual\",axis=1)\n",
        "\n",
        "\n",
        "  from catboost import CatBoostRegressor\n",
        "  from catboost import Pool\n",
        "\n",
        "  cat_model = CatBoostRegressor(cat_features=[\"GVKEY\",\"industry_fama\"],random_seed=2021,boosting_type=\"Plain\",bootstrap_type =\"MVS\",\n",
        "                              colsample_bylevel =0.09625657571631001, depth=10, iterations=13000,one_hot_max_size = 5000,\n",
        "                              max_ctr_complexity=0, early_stopping_rounds=250)\n",
        "\n",
        "  pool_val = Pool(validatation_x,validatation_y,cat_features=[\"GVKEY\",\"industry_fama\"])\n",
        "\n",
        "  cat_model.fit(training_x,training_y,eval_set=pool_val,verbose=False)\n",
        "\n",
        "  print(cat_model.best_iteration_)\n",
        "  print(cat_model.get_best_score())\n",
        "\n",
        "  test_pred = cat_model.predict(test_x)\n",
        "  return test_pred\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1616408512607
        },
        "id": "ChRQDZfIA6pN"
      },
      "outputs": [],
      "source": [
        "# Mase function\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "def mase(actual_eps_training,lagged_eps,model_predicted,actual_eps_test):\n",
        "  '''\n",
        "  Calculates the Mean Absolute scaled error per Hyndman definition\n",
        "  actuals_eps_training = EPS actual from training\n",
        "  Lagged_eps = Lagged EPS from training (naive forecast)\n",
        "  Model_predicted = Model predictions in the test set\n",
        "  Actual_eps_test = The actual EPS from the test set  \n",
        "   '''\n",
        "  mae = mean_absolute_error(actual_eps_training,lagged_eps)\n",
        "  q = (actual_eps_test - model_predicted) /mae\n",
        "  mase = np.mean(np.abs(q))\n",
        "  return mase\n",
        "\n",
        "\n",
        "  # Metric Dataframe\n",
        "def metric_dataframe (test_predicted,industri, fil=\"/content/drive/MyDrive/Cand.fælles/Speciale/datarobot_input/input.csv.zip\"):\n",
        "\n",
        "  '''fil : Indsæt stien til den fil der indeholder data før ML rensning\n",
        "    test_predicted : Henvis til et array af predicted værdier på testsættet\n",
        "    industri (string): Den industri der skal køres performance på'''\n",
        "\n",
        "  df = pd.read_csv(fil)\n",
        "  df[\"Forecasttidspunkt\"] = pd.to_datetime(df[\"Forecasttidspunkt\"])\n",
        "  df.set_index(\"Forecasttidspunkt\",inplace=True)\n",
        "  df.sort_index(inplace=True)\n",
        "  df= df[df.industry_fama ==industri]\n",
        "  træning_slut = \"2018-06-30\"\n",
        "  test_start = \"2018-09-30\"\n",
        "  train_df = df.loc[:træning_slut,:]\n",
        "  test_df = df.loc[test_start:,:]\n",
        "  test_df[\"Model_predicted\"] = test_predicted\n",
        "  test_df.dropna(subset=[\"analyst_EPS_mean\"],inplace=True)\n",
        "  return train_df,test_df\n",
        "\n",
        "  # Metric Calculations\n",
        "def metric_calculations (metric_test_df,metric_train_df):\n",
        "  # Mae\n",
        "  analytiker_mae = mean_absolute_error(metric_test_df[\"EPS_actual\"],metric_test_df[\"analyst_EPS_mean\"])\n",
        "  model_mae = mean_absolute_error(metric_test_df[\"EPS_actual\"],metric_test_df[\"Model_predicted\"])\n",
        "  # RMSE\n",
        "  analytiker_rmse = mean_squared_error(metric_test_df[\"EPS_actual\"],metric_test_df[\"analyst_EPS_mean\"],squared=False)\n",
        "  model_rmse = mean_squared_error(metric_test_df[\"EPS_actual\"],metric_test_df[\"Model_predicted\"],squared=False)\n",
        "\n",
        "  # Mase\n",
        "  analytiker_mase = mase(metric_train_df[\"EPS_actual\"],metric_train_df[\"EPS_lagged\"],metric_test_df[\"analyst_EPS_mean\"],metric_test_df[\"EPS_actual\"]) \n",
        "  model_mase = mase(metric_train_df[\"EPS_actual\"],metric_train_df[\"EPS_lagged\"],metric_test_df[\"Model_predicted\"],metric_test_df[\"EPS_actual\"]) \n",
        "  \n",
        "\n",
        "\n",
        "  metric_df = pd.DataFrame.from_dict({\"MAE\":[analytiker_mae,model_mae],\"RMSE\": [analytiker_rmse,model_rmse],\"MASE\": [analytiker_mase,model_mase]})\n",
        "  metric_df.index = [\"Analytiker\",\"Model\"]\n",
        "  return metric_df\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1616408512716
        },
        "id": "PqzQtJIIMP9y"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xh_Ib15bTNSw"
      },
      "source": [
        "# Industri model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "gather": {
          "logged": 1616408516897
        },
        "id": "k-4UxWX3VmN1",
        "outputId": "7fade9ea-cf22-4c2b-ce9a-6dbd4201aa9e"
      },
      "outputs": [],
      "source": [
        "! pip install catboost\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC4dsXwr9BHn"
      },
      "source": [
        "## 1Q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "gather": {
          "logged": 1616408915020
        },
        "id": "D_nthXTIQ25m",
        "outputId": "d9704322-53af-48d1-c4e9-9fa19551e564"
      },
      "outputs": [],
      "source": [
        "industrier_liste = ['Healthcare', 'Manufacturing', 'Business Equipment',\n",
        "       'Wholesale/Retail', 'finance', 'Chemicals and Allied products',\n",
        "       'Consumer Nondurables', 'Energy', 'telecom', 'Consumer durables']\n",
        "\n",
        "Q1_testpred = {}\n",
        "Q1_train ={}\n",
        "Q1_test ={}\n",
        "Q1_performance={} \n",
        "\n",
        "for industri__valg in industrier_liste:\n",
        "\n",
        "  fil_sti = \"input.csv.zip\"\n",
        "  Q1_testpred[f'{industri__valg}'] = ml_pipeline(fil_sti,industri=f'{industri__valg}')\n",
        "  Q1_train[f'{industri__valg}'],Q1_test[f'{industri__valg}'] = metric_dataframe(test_predicted=Q1_testpred[f'{industri__valg}'],fil=fil_sti,industri=f'{industri__valg}')\n",
        "  Q1_performance[f'{industri__valg}'] = metric_calculations(Q1_test[f'{industri__valg}'],Q1_train[f'{industri__valg}'])\n",
        "\n",
        "# Joblib save output\n",
        "\n",
        "joblib.dump(Q1_testpred,\"Q1_testpred_industri.pkl\")\n",
        "joblib.dump(Q1_train,\"Q1_train_industri.pkl\")\n",
        "joblib.dump(Q1_test,\"Q1_test_industri.pkl\")\n",
        "joblib.dump(Q1_performance,\"Q1_performance_industri.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7csF-UQRID5"
      },
      "source": [
        "## Q2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "gather": {
          "logged": 1616409215442
        },
        "id": "kbszYvLdRJ-R",
        "outputId": "1fa27de9-9219-4820-df87-10cce9319769"
      },
      "outputs": [],
      "source": [
        "industrier_liste = ['Healthcare', 'Manufacturing', 'Business Equipment',\n",
        "       'Wholesale/Retail', 'finance', 'Chemicals and Allied products',\n",
        "       'Consumer Nondurables', 'Energy', 'telecom', 'Consumer durables']\n",
        "\n",
        "Q2_testpred = {}\n",
        "Q2_train ={}\n",
        "Q2_test ={}\n",
        "Q2_performance={} \n",
        "\n",
        "for industri__valg in industrier_liste:\n",
        "\n",
        "  fil_sti = \"input_2Q.csv.zip\"\n",
        "  Q2_testpred[f'{industri__valg}'] = ml_pipeline(fil_sti,industri=f'{industri__valg}')\n",
        "  Q2_train[f'{industri__valg}'],Q2_test[f'{industri__valg}'] = metric_dataframe(test_predicted=Q2_testpred[f'{industri__valg}'],fil=fil_sti,industri=f'{industri__valg}')\n",
        "  Q2_performance[f'{industri__valg}'] = metric_calculations(Q2_test[f'{industri__valg}'],Q2_train[f'{industri__valg}'])\n",
        "\n",
        "joblib.dump(Q2_testpred,\"Q2_testpred_industri.pkl\")\n",
        "joblib.dump(Q2_train,\"Q2_train_industri.pkl\")\n",
        "joblib.dump(Q2_test,\"Q2_test_industri.pkl\")\n",
        "joblib.dump(Q2_performance,\"Q2_performance_industri.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAa90bqYSP5m"
      },
      "source": [
        "## Q4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "gather": {
          "logged": 1616409540070
        },
        "id": "ZYV0qSlFSR_w",
        "outputId": "e63fd3b6-412f-4236-b120-878789631c12"
      },
      "outputs": [],
      "source": [
        "industrier_liste = ['Healthcare', 'Manufacturing', 'Business Equipment',\n",
        "       'Wholesale/Retail', 'finance', 'Chemicals and Allied products',\n",
        "       'Consumer Nondurables', 'Energy', 'telecom', 'Consumer durables']\n",
        "\n",
        "Q4_testpred = {}\n",
        "Q4_train ={}\n",
        "Q4_test ={}\n",
        "Q4_performance={} \n",
        "\n",
        "for industri__valg in industrier_liste:\n",
        "\n",
        "  fil_sti = \"input_4Q.csv.zip\"\n",
        "  Q4_testpred[f'{industri__valg}'] = ml_pipeline(fil_sti,industri=f'{industri__valg}')\n",
        "  Q4_train[f'{industri__valg}'],Q4_test[f'{industri__valg}'] = metric_dataframe(test_predicted=Q4_testpred[f'{industri__valg}'],fil=fil_sti,industri=f'{industri__valg}')\n",
        "  Q4_performance[f'{industri__valg}'] = metric_calculations(Q4_test[f'{industri__valg}'],Q4_train[f'{industri__valg}'])\n",
        "\n",
        "\n",
        "joblib.dump(Q4_testpred,\"Q4_testpred_industri.pkl\")\n",
        "joblib.dump(Q4_train,\"Q4_train_industri.pkl\")\n",
        "joblib.dump(Q4_test,\"Q4_test_industri.pkl\")\n",
        "joblib.dump(Q4_performance,\"Q4_performance_industri.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1616410949755
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "Q1_performance[\"Business Equipment\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Industrier.ipynb",
      "provenance": []
    },
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}